{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6de93c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3.2:1b\")\n",
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52a05885",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b75c079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading research papers...\n",
      "Building index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying transformations: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s]\n",
      "\n",
      "\u001b[A2026-02-14 13:37:33,644 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:33,825 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:33,978 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,127 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,263 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,415 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,559 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,705 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:34,872 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:35,034 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:35,182 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:35,329 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:35,469 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\u001b[A2026-02-14 13:37:35,537 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 132/132 [00:05<00:00, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index stored.\n"
     ]
    }
   ],
   "source": [
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "\n",
    "    print(\"Loading research papers...\")\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "    print(\"Building index...\")\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        transformations=[node_parser],\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "    print(\"Index stored.\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading existing index...\")\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=PERSIST_DIR\n",
    "    )\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ce110ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 13:38:30,208 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63efeccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 13:39:04,746 - INFO - HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2026-02-14 13:39:21,494 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "\n",
      "file_path: c:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\data\\yolo.pdf\n",
      "\n",
      "YOLO stands for You Only Look Once. It is a real-time object detection system that detects and tracks objects in an image or video.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m query.lower() == \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:44\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     43\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m dispatcher.event(\n\u001b[32m     46\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     47\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:196\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    194\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    195\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._response_synthesizer.synthesize(\n\u001b[32m    198\u001b[39m         query=query_bundle,\n\u001b[32m    199\u001b[39m         nodes=nodes,\n\u001b[32m    200\u001b[39m     )\n\u001b[32m    201\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:149\u001b[39m, in \u001b[36mRetrieverQueryEngine.retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_node_postprocessors(nodes, query_bundle=query_bundle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:210\u001b[39m, in \u001b[36mBaseRetriever.retrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    207\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    208\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    209\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m         nodes = \u001b[38;5;28mself\u001b[39m._handle_recursive_retrieval(query_bundle, nodes)\n\u001b[32m    212\u001b[39m         retrieve_event.on_end(\n\u001b[32m    213\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    214\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:115\u001b[39m, in \u001b[36mVectorIndexRetriever._retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle.embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle.embedding_strs) > \u001b[32m0\u001b[39m:\n\u001b[32m    110\u001b[39m         query_bundle.embedding = (\n\u001b[32m    111\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_model.get_agg_embedding_from_queries(\n\u001b[32m    112\u001b[39m                 query_bundle.embedding_strs\n\u001b[32m    113\u001b[39m             )\n\u001b[32m    114\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:231\u001b[39m, in \u001b[36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[39m\u001b[34m(self, query_bundle_with_embeddings)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_nodes_with_embeddings\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[32m    229\u001b[39m ) -> List[NodeWithScore]:\n\u001b[32m    230\u001b[39m     query = \u001b[38;5;28mself\u001b[39m._build_vector_store_query(query_bundle_with_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m     nodes_to_fetch = \u001b[38;5;28mself\u001b[39m._determine_nodes_to_fetch(query_result)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nodes_to_fetch:\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# Fetch any missing nodes from the docstore and insert them into the query result\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\vector_stores\\simple.py:303\u001b[39m, in \u001b[36mSimpleVectorStore.query\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     top_similarities, top_ids = get_top_k_mmr_embeddings(\n\u001b[32m    296\u001b[39m         query_embedding,\n\u001b[32m    297\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m         mmr_threshold=mmr_threshold,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query.mode == VectorStoreQueryMode.DEFAULT:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     top_similarities, top_ids = \u001b[43mget_top_k_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid query mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery.mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\query\\embedding_utils.py:31\u001b[39m, in \u001b[36mget_top_k_embeddings\u001b[39m\u001b[34m(query_embedding, embeddings, similarity_fn, similarity_top_k, embedding_ids, similarity_cutoff)\u001b[39m\n\u001b[32m     29\u001b[39m similarity_heap: List[Tuple[\u001b[38;5;28mfloat\u001b[39m, Any]] = []\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings_np):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     similarity = \u001b[43msimilarity_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m similarity_cutoff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m similarity > similarity_cutoff:\n\u001b[32m     33\u001b[39m         heapq.heappush(similarity_heap, (similarity, embedding_ids[i]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Downloads\\LlamaIndex-RAG\\venv\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:67\u001b[39m, in \u001b[36msimilarity\u001b[39m\u001b[34m(embedding1, embedding2, mode)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.dot(embedding1, embedding2)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     product = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     norm = np.linalg.norm(embedding1) * np.linalg.norm(embedding2)\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m product / norm\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nAsk about YOLO or Transformers (type 'exit'): \")\n",
    "\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    print(\"\\nAnswer:\\n\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e70e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
